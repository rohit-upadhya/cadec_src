{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/simple-rag/'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "os.chdir(gdrive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install optimum\n",
    "!pip install auto-gptq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# change directory to the root of your project\n",
    "%cd /content/gdrive/MyDrive/cadec_src/\n",
    "\n",
    "print(os.getcwd())\n",
    "sys.path.insert(0, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.preprocess.preprocess_data import PreprocessData\n",
    "\n",
    "preprocess_data = PreprocessData()\n",
    "data_points = preprocess_data.preprocess_data()\n",
    "print(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from src.utils.prompt_builder import Prompter\n",
    "# from src.utils.load_input import InputLoader\n",
    "\n",
    "# prompt_template = InputLoader().load_file(\"/content/gdrive/MyDrive/cadec_src/prompt_tempaltes.yaml\").get(\"medical_entity_extraction\", {})\n",
    "\n",
    "# prompter = Prompter(prompt_template)\n",
    "\n",
    "# for item in data_points:\n",
    "#   item = \"\\n\".join(item)\n",
    "\n",
    "# print(data_points)\n",
    "# prompt = prompter.build_chat_prompt(item)\n",
    "\n",
    "\n",
    "#print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# input_text = tokenizer.convert_chat_messages(prompt)\n",
    "# def apply_chat_template(\n",
    "#         input_prompt_dict_list: list[dict],\n",
    "#     ):\n",
    "#         prompt_text = \"\"\n",
    "\n",
    "#         for prompt_item in input_prompt_dict_list:\n",
    "#             if \"system\" in prompt_item[\"role\"]:\n",
    "#                 prompt_text = f\"{prompt_text}<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n{prompt_item['content']}<|eot_id|>\\n\"\n",
    "#             elif \"user\" in prompt_item[\"role\"]:\n",
    "#                 prompt_text = f\"{prompt_text}<|start_header_id|>user<|end_header_id|>\\n{prompt_item['content']}<|eot_id|>\\n\"\n",
    "#             elif \"assistant\" in prompt_item[\"role\"]:\n",
    "#                 prompt_text = f\"{prompt_text}<|start_header_id|>assistant<|end_header_id|>\\n{prompt_item['content']}<|eot_id|>\\n\"\n",
    "#         prompt_text = f\"{prompt_text}<|start_header_id|>assistant<|end_header_id|>\"\n",
    "#         return prompt_text\n",
    "# input_text = apply_chat_template(prompt)\n",
    "# print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.inference.local_model import HuggingFaceModels\n",
    "import torch\n",
    "\n",
    "\n",
    "device: torch.device = torch.device(\"cuda\")\n",
    "huggingface_obj=HuggingFaceModels(\n",
    "            # model_name_or_path=\"TheBloke/Asclepius-13B-GPTQ\",\n",
    "            device = device,\n",
    "            model_name_or_path=\"starmpcc/Asclepius-13B\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.preprocess.clean_data import CleanData\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "clean_data = CleanData(device=device, huggingface_obj=huggingface_obj)\n",
    "\n",
    "cleaned_data = []\n",
    "for item in data_points:\n",
    "  cleaned_data.append(clean_data.clean_data(item))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
